{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load stopwords into set (from http://www.ranks.nl/stopwords)\n",
    "with open('stopwords') as f:\n",
    "    sw = f.read()\n",
    "stopwords = set(sw.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(_txt):\n",
    "    # string.punctuaction => '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    punc = string.punctuation\n",
    "    trans = {ord(c): ' ' for c in punc}\n",
    "    trans[ord(\"'\")] = None\n",
    "\n",
    "    s = unidecode(_txt).translate(trans)\n",
    "    s = re.sub(r'\\d+', '', s)\n",
    "    return ' '.join(s.lower().split())\n",
    "\n",
    "def remove_stopwords(_txt):\n",
    "    return ' '.join(w for w in _txt.split() if not w in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bounties_project_overview_for_research.txt') as f:\n",
    "    txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove questions\n",
    "questions_raw = '''What type of apps do you build:\n",
    "Eg: Are they primarily blockchain-based? Blockchain backend with a \"regular\" web front-end? Front-end that uses the blockchain directly via Metamask et al?\n",
    "How do you test things which interact with the blockchain:\n",
    "Automated testing? How do the facilitate manual testing? (to get an idea how sophisticated their dev process is)\n",
    "Brief walk through of the tools you use daily\n",
    "If not already mentioned, are there any libraries you rely on regularly?\n",
    "What isn't possible with current tools, but would be nice\n",
    "Try to remember the last time you developed a feature for ethereum and you ran into some unexpected obstacle. What was it? How did you feel?\n",
    "This Q used to be: what is most frustrating about developing on ETH? (changed so we’re not asking a leading question).\n",
    "Are you running into problems with any of the following:\n",
    "What tool’s / libraries are most frustrating\n",
    "How could they be improved\n",
    "What surprised you on the other end, what was way easier than expected?\n",
    "What process do you use for validating the security of your smart contracts?\n",
    "What was the hardest part about learning to develop with Ethereum\n",
    "What was the first thing you built related to Ethereum, and when did you build it? (NEW)\n",
    "What applications are you most excited about in the near term (ie. what do you think will be working soon)\n",
    "Who are other people you think we should talk to (alternative:  Who is the best developer you know)\n",
    "What other questions should we be asking?\n",
    "What really pisses you off about ETH development\n",
    "'''\n",
    "questions = []\n",
    "for q in questions_raw.split('\\n'):\n",
    "    questions.append(clean_text(q))\n",
    "\n",
    "def remove_questions(_txt):\n",
    "    for q in questions:\n",
    "        _txt = re.sub(q, '', _txt)\n",
    "    return _txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('contacts.txt') as f:\n",
    "    contacts_raw = f.read()\n",
    "\n",
    "contacts = set()\n",
    "for c in contacts_raw.split('\\n'):\n",
    "    m = re.match('[0-9]+\\. ([a-zA-Z ]+).*', c)\n",
    "    if m is not None:\n",
    "        contacts.add(m.group(1).lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chain the cleanup\n",
    "txt2 = remove_stopwords(remove_questions(clean_text(txt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(nltk.word_tokenize(txt2))\n",
    "counter = Counter()\n",
    "for b in bigrams:\n",
    "    counter[b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('e', 'g'), 96),\n",
       " (('smart', 'contracts'), 73),\n",
       " (('smart', 'contract'), 58),\n",
       " (('right', 'now'), 45),\n",
       " (('state', 'channels'), 40),\n",
       " (('gas', 'limit'), 34),\n",
       " (('open', 'source'), 32),\n",
       " (('unit', 'tests'), 24),\n",
       " (('best', 'practices'), 24),\n",
       " (('code', 'coverage'), 21),\n",
       " (('front', 'end'), 21),\n",
       " (('dont', 'know'), 20),\n",
       " (('ui', 'issues'), 20),\n",
       " (('web', 'js'), 19),\n",
       " (('developing', 'eth'), 18),\n",
       " (('make', 'sure'), 18),\n",
       " (('frustrating', 'developing'), 17),\n",
       " (('geth', 'parity'), 17),\n",
       " (('chain', 'computation'), 17),\n",
       " (('json', 'rpc'), 17)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams = nltk.trigrams(nltk.word_tokenize(txt2))\n",
    "counter = Counter()\n",
    "for b in bigrams:\n",
    "    counter[b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('frustrating', 'developing', 'eth'), 17),\n",
       " (('specifically', 'talk', 'ui'), 15),\n",
       " (('talk', 'ui', 'issues'), 15),\n",
       " (('ui', 'issues', 'scaling'), 15),\n",
       " (('developing', 'eth', 'specifically'), 14),\n",
       " (('eth', 'specifically', 'talk'), 14),\n",
       " (('https', 'github', 'com'), 14),\n",
       " (('hardest', 'part', 'teaching'), 9),\n",
       " (('code', 'coverage', 'tool'), 7),\n",
       " (('chain', 'computation', 'state'), 6),\n",
       " (('computation', 'state', 'channels'), 6),\n",
       " (('people', 'think', 'talk'), 6),\n",
       " (('writing', 'smart', 'contracts'), 6),\n",
       " (('tools', 'libraries', 'frameworks'), 6),\n",
       " (('static', 'analysis', 'tools'), 5),\n",
       " (('ui', 'issues', 'struggled'), 5),\n",
       " (('exist', 'right', 'now'), 5),\n",
       " (('x', 'code', 'coverage'), 4),\n",
       " (('questions', 'frustrating', 'developing'), 4),\n",
       " (('gas', 'limit', 'chain'), 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate inteview into docs (nees more work?)\n",
    "docs_raw = []\n",
    "current = None\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for l in txt.split('\\n'):\n",
    "    if l == '%%%%':\n",
    "        if current is not None and len(current) > 1:\n",
    "            docs_raw.append(current)\n",
    "        current = []\n",
    "    if current is not None and l != '':\n",
    "        current.append(l)\n",
    "\n",
    "if current is not None and len(current) > 1:\n",
    "    docs_raw.append(current)\n",
    "\n",
    "docs = []\n",
    "for doc in docs_raw:\n",
    "    docs.append(remove_stopwords(remove_questions(clean_text('\\n'.join(doc)))).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdict = corpora.Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [gdict.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=gdict, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.076*\"bounty\" + 0.074*\"geth\" + 0.072*\"remix\" + 0.072*\"data\" + 0.071*\"parity\" + 0.067*\"really\" + 0.066*\"tools\" + 0.063*\"metamask\" + 0.063*\"need\" + 0.060*\"chain\"'),\n",
       " (1,\n",
       "  '-0.406*\"wasm\" + -0.135*\"ewasm\" + 0.115*\"john\" + -0.108*\"opcodes\" + 0.102*\"marcus\" + -0.081*\"stu\" + -0.081*\"stack\" + 0.081*\"metamask\" + -0.080*\"greg\" + -0.080*\"easily\"'),\n",
       " (2,\n",
       "  '-0.227*\"marcus\" + -0.187*\"john\" + -0.143*\"ricardo\" + -0.118*\"david\" + -0.110*\"remix\" + -0.110*\"limit\" + 0.101*\"erc\" + -0.092*\"computation\" + -0.089*\"ethers\" + -0.081*\"frustrating\"'),\n",
       " (3,\n",
       "  '-0.185*\"wasm\" + -0.153*\"david\" + 0.138*\"zeppelin\" + -0.115*\"chainsafe\" + -0.111*\"geth\" + -0.103*\"stu\" + -0.094*\"greg\" + -0.093*\"metamask\" + -0.093*\"phishing\" + -0.088*\"parity\"'),\n",
       " (4,\n",
       "  '-0.141*\"john\" + -0.133*\"bounty\" + -0.112*\"phishing\" + -0.097*\"gitcoin\" + 0.092*\"auction\" + -0.091*\"open\" + 0.085*\"matt\" + 0.083*\"ricardo\" + -0.082*\"mew\" + 0.081*\"whisper\"'),\n",
       " (5,\n",
       "  '-0.215*\"wasm\" + 0.146*\"david\" + 0.131*\"land\" + 0.131*\"chainsafe\" + -0.128*\"ewasm\" + 0.125*\"auction\" + 0.112*\"stu\" + -0.107*\"ast\" + -0.106*\"marcus\" + -0.106*\"static\"'),\n",
       " (6,\n",
       "  '-0.225*\"david\" + -0.212*\"chainsafe\" + -0.190*\"stu\" + -0.159*\"greg\" + -0.154*\"marcus\" + -0.124*\"matt\" + -0.111*\"ricardo\" + -0.106*\"wasm\" + 0.097*\"peter\" + -0.093*\"opcodes\"'),\n",
       " (7,\n",
       "  '0.185*\"wasm\" + -0.174*\"chainsafe\" + -0.158*\"stu\" + -0.150*\"david\" + -0.141*\"greg\" + 0.123*\"land\" + 0.116*\"matt\" + 0.110*\"sina\" + 0.108*\"auction\" + -0.105*\"geth\"'),\n",
       " (8,\n",
       "  '0.130*\"whisper\" + -0.121*\"wyvern\" + 0.110*\"chainsafe\" + 0.105*\"stu\" + -0.096*\"metamask\" + 0.094*\"sina\" + -0.093*\"wasm\" + -0.093*\"user\" + 0.092*\"david\" + -0.091*\"rpc\"'),\n",
       " (9,\n",
       "  '0.166*\"embark\" + 0.161*\"whisper\" + -0.130*\"wasm\" + 0.114*\"swarm\" + -0.107*\"phishing\" + 0.095*\"chainsafe\" + 0.086*\"stu\" + 0.084*\"remix\" + 0.083*\"david\" + 0.077*\"metamask\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.ldamulticore.LdaMulticore(corpus, id2word=gdict, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
